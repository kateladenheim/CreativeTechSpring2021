<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>KLCRTECH3</title>
        <link rel="stylesheet" href="styles.css">
        <link rel="stylesheet" href="https://use.typekit.net/kfi0pqz.css">
    </head>
    <body>

        <div>
            <h3 class="name-subtitle">kate ladenheim</h3>
            <h1>creative technology 3</h1>
        </div>
        <div class="hw-section-title">
            <h2>week 2 // Reading Quotes & Responses</h1>
                <p>>>> Assignment: <i>You Look Like a Thing and I Love You,</i>Chapter 7: Unfortunate Shortcuts</p>
        </div>

        <div>
            <div class="quote-container">
                <p class = "quote">"AIs are so prone to finding and using human bias that the state of New York recently released guidance advising insurance companies that if they analyze the sort of “alternative data” that would give an AI a clue about what kind of neighborhood a person lives in, they might be violating anti-discrimination laws. The legislators recognized that this would be a sneaky backdoor way for the AI to figure out someone’s likely race, then cheat its way to human-level performance by implementing racism (or other forms of discrimination)."</p>
                <p class="quote-response">I'm shocked but excited to hear that AI is starting to be legislated. For me, a lot of these questions around AI and bias come back to concepts around authorship and responsibility. Abstracting the work of an AI from its creator doesn't recognize that the AI was designed by people who, as long as the technology is imperfect (forever) will need to monitor its effects, both savory and unsavory. It also makes me think a lot of Ibram X. Kendi's <i>How To Be An Anti-Racist,</i> — it's not enough to ignore or claim that there is no bias, you have to be actiely anti-biased in your design and resulting policy.</p>
            </div>
            <div>
                <p class = "quote">"People treat these kinds of algorithms as if they are making recommendations, but it’s a lot more accurate to say that they’re making predictions. They’re not telling us what the best decision would be—they’re just learning to predict human behavior. Since humans tend to be biased, the algorithms that learn from them will also tend to be biased unless humans take extra care to find and remove the bias."</p>
                <p class="quote-response">I find this distinction clarifying in interpreting the actions of AI, and also in guiding the design of AI to prevent bias. Technology still maintains a certain affective magic to it in its materiality, so it's easy to attribute more than what's there into its programs. Further, since it attempts to predict our behavior, it's easy to read human-like qualities into it. I think it's important to take responsibility for AI a creation of humans, but to understand its differences in process and operation as critical towards fighting bias — and, frankly, improving its functionality.</p>
            </div>
            <div>
                <p class = "quote">“Another way people are detecting bias (and other unfortunate behavior) is by designing algorithms that can explain how they arrived at their solutions. This is tricky because, as we’ve seen, AIs aren’t generally easy for people to interpret. And as we know from the Visual Chatbot discussed in chapter 4, it’s tough to train an algorithm that can sensibly answer questions about how it sees the world. The most progress has been made with image recognition algorithms, which can point to the bits of the image that it was paying attention to or can show us the kinds of features it was looking for.”</p>
                <p class="quote-response">This is a method of dismantling bias in AI that really excites me — one of demystifying its processes and creation so that it becomes less of a black box and more of an open book. I think this is also essential to de-fetishizing programming and the creation of technical tools. Is there a way we can simultaneously hold the talent and rigor of creators of complex technical systems, but recognize that they do not need to hard their talent and knowledge?</p>
            </div>
        </div>

        <div>
            <p>
                <a href="https://kateladenheim.github.io/MDP-CreativeTech/rube-goldberg/rb-start.html">Week 2 Project: The Web as Rube Goldberg Machine</a> // <a href="https://kateladenheim.github.io/MDP-CreativeTech/"index.html>Home</a>
            </p>
        </div>

    </body>
</html>